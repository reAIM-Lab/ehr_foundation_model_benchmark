
---

# 🩺 Context Clues: Linear Probing for EHR Embeddings

This code performs **linear probing** using precomputed **embedding representations of patient health records** to evaluate downstream task performance across different phenotype prediction tasks (e.g., AMI, T2DM). It supports embeddings generated by foundation models (e.g., Mamba-EHRShot)

---

## 🚀 Usage

```bash
python main.py \
  --input_meds /path/to/meds/dataset \
  --task AMI \
  --model mamba-tiny-4096-clmbr \
  --model_type mamba-ehrshot \
  --seed 123
```

If running all tasks at once, and generating metrics using MEDS-evaluation

```bash
./phenotype_predictions.sh
```

### Arguments

| Argument        | Default | Description                                                                 |
|-----------------|---------|-----------------------------------------------------------------------------|
| `--input_meds`  | `/data2/...` | Path to the processed dataset containing embeddings and label files         |
| `--task`        | `AMI`   | Name of the task (e.g., AMI, T2DM, etc.)                                    |
| `--model`       | `mamba-tiny-4096-clmbr` | Model identifier used for Huggingface                        |
| `--model_type`  | `mamba-ehrshot` | Label used for storing embeddings, saving predictions                 |
| `--seed`        | `123`   | Random seed for reproducibility                                              |

---

## 📁 File Structure

```
.
├── utils.py                # Contains helper functions and LR model definition
├── main.py     # Main script
├── models/
│   └── <task_name>/        # Stores trained models for each task
├── predictions/
│   └── <task_name>/        # Stores prediction outputs
├── checkpoints/            # Stores temporary model checkpoints
```

---

## 🧪 Supported Tasks

Currently, the following phenotype tasks are supported via in-house cohorts:

- AMI
- Celiac
- CLL
- HTN
- Ischemic_Stroke
- MASLD
- Osteoporosis
- Pancreatic_Cancer
- SLE
- T2DM

---

## 🛠️ Notes

- The MEDS data is loaded from:
  - `post_transform/data/train/`
  - `post_transform/data/tuning/`
  - `post_transform/data/held_out/`
- Adapt `utils.py` if using a different model (Change global `BATCH_SIZE` and `CONTEXT_LENGTH` parameters).
