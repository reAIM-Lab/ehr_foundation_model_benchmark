 1. Fixed SurvivalCalculator to Work Without Pre-existing value_bins_dict

  Changes Made:
  - Removed value_bins_dict parameter from SurvivalCalculator.__init__()
  - Dynamic numerical code detection: Now includes all codes with numeric_value that can be converted to float
  - Direct code usage: Lab codes don't use ontology hierarchy - directly use event.code
  - Simplified filtering: if code_whitelist is None or event.code in code_whitelist

  Why: The original code assumed value_bins_dict existed at initialization time, but during the fitting process, we need to discover numerical codes dynamically and generate bins
  based on actual data.

  2. Generated Value Bins During Task Fitting Process

  New Methods Added:
  - _create_robust_bins_static(): Static method to generate bins from value samples
  - _create_robust_bins(): Instance method wrapper
  - Enhanced fit_pretraining_task_info() to generate value bins dynamically

  Dynamic Bin Generation Process:
  # Collect value samples during prefit_motor_map
  task_value_samples = [ReservoirSampler(100_000) for _ in range(len(tasks))]

  # Generate bins from actual data
  if len(task_value_samples[i].samples) > 0:
      bins, valid_bins = MOTORTask._create_robust_bins_static(value_samples, num_value_bins)
      task_value_bins[task] = {
          'bins': bins,
          'valid_bins': valid_bins,
          'num_valid_bins': len(valid_bins)
      }

  Why: We need to discover numerical codes and generate appropriate bins based on the actual data distribution, not pre-defined bins.

  3. Handled Duplicate Bins and Extreme Values Properly

  Robust Binning Strategy:
  - Extreme value boundaries: -inf to +inf as first and last bin boundaries
  - Duplicate bin detection: Identify bins where bins[i] == bins[i+1]
  - Valid bin tracking: Maintain valid_bins list containing only non-duplicate bin indices
  - Fallback handling: Graceful degradation for edge cases

  Example Handling:
  # Input: [0.0, 30.0, 30.0, 30.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35100.0]
  # Bins: [-inf, 30.0, 30.0, 30.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, inf]  
  # Valid bins indices: [0, 3, 9]  # Only 3 valid bins out of 10

  Why: Real-world lab data often has repeated values or extreme outliers that would break naive percentile-based binning.

  4. Implemented Comprehensive task.cleanup() Method for Value Handling

  Extended cleanup() Method:
  - Value sparse matrix processing: Convert value_sparse and value_bin_sparse to dense tensors
  - 4D tensor creation: value_is_event with shape [pred_points, time_bins, value_bins, numerical_tasks]
  - Censoring logic: For censored cases in last time bin, mark all valid value bins
  - Task mapping: Map between global task indices and numerical task indices

  New Return Values:
  return {
      "is_event": is_event,                    # Original: [pred_points, time_bins, tasks]
      "is_censored": is_censored,              # Original: [pred_points, tasks] 
      "censor_time_ratio": censor_time_ratio,  # Original: for linear interpolation
      "value_is_event": value_is_event,        # New: [pred_points, time_bins, value_bins, numerical_tasks]
      "value_is_censored": value_is_censored   # New: [pred_points, numerical_tasks]
  }

  Why: The transformer's forward method needs properly formatted tensors for both time-only and time-value loss computation.

  5. Enhanced Data Processing Pipeline

  Updated Methods:
  - start_subject(): Added value sparse matrix initialization
  - start_batch(): Added batch-level value sparse matrices
  - add_event(): Enhanced to handle value binning for numerical tasks
  - add_subject_labels(): Extended to propagate value data to batch level
  - get_batch_data(): Include value sparse matrices in return

  Value Processing Flow:
  # During event processing
  if value is not None and event_name in self.task_value_bins:
      numerical_j = self.numerical_task_to_index_map[event_name]
      self.per_subject_value_sparse["data"].append(value)

      # Determine value bin using robust binning
      bins_info = self.task_value_bins[event_name]
      value_bin = self._get_value_bin(value, bins_info['bins'], bins_info['valid_bins'])
      self.per_subject_value_bin_sparse["data"].append(value_bin)

  Why: The entire data pipeline needs to track both time-to-event and value information for numerical codes.

  6. Enhanced Filtering Criteria

  New Filtering Logic:
  # Apply filtering based on whether task has numerical values
  value_sample_count = len(task_value_samples[i].samples) if i < len(task_value_samples) else 0

  if value_sample_count > 0:
      # This is a numerical task: tte > 1/1000 & value count > 1000
      if frac_events < 1 / 1000 or value_sample_count < 1000:
          continue  # Filter out
  else:
      # This is a non-numerical task: original threshold
      if frac_events < 1 / 1000:
          continue  # Filter out

  Why: Numerical tasks need both sufficient time-to-event statistics AND sufficient value diversity (>1000 value samples) to create meaningful bins.

  7. Maintained Full Backward Compatibility

  Preserved Functionality:
  - Non-numerical codes work exactly as before
  - Original time-only prediction logic unchanged
  - Existing transformer architecture maintained
  - All processor.py methods work without changes

  Integration Points:
  - prepare_motor.py: No changes needed - uses MOTORTask.fit_pretraining_task_info()
  - pretrain_motor.py: No changes needed - uses processor.collate() and task.cleanup()
  - Configuration: Seamlessly handles both numerical and non-numerical tasks

  8. Optimized for Efficiency

  Performance Optimizations:
  - Vectorized operations in cleanup() method using PyTorch tensors
  - Sparse matrix storage for memory efficiency during data collection
  - Lazy evaluation - value bins only generated for tasks with sufficient data
  - Minimal overhead - non-numerical tasks have no additional processing cost

  The implementation is now fully compatible with your existing prepare_motor.py and pretrain_motor.py scripts, handles all the edge cases you mentioned (extreme values, duplicate
  bins), and dynamically discovers and processes numerical lab codes without requiring pre-existing value_bins_dict input.