Using configuration:
  COHORT_BASE_DIR: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
  PRETRAINING_DATA: /user/zj2398/cache/mtpp_8k
  OMOP_MEDS_READER: /user/zj2398/cache/mimic/meds_v0.6_reader
  NUM_PROC: 64
  TOKENS_PER_BATCH: 65536
  OBSERVATION_WINDOW: Not specified
  USE_LINEAR_INTERPOLATION: false

Discovering prediction tasks...
[1] Found task: celiac
[2] Found task: masld
[3] Found task: stroke
[1/3] Processing task: celiac
cohort_base_dir: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
Task directory: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/
Running mtpp feature generation for celiac...
Executing command: python -u -m femr.omop_meds_tutorial.motor_evaluation.generate_mtpp_features       --pretraining_data "/user/zj2398/cache/mtpp_8k"       --model_path "/user/zj2398/cache/mtpp_8k/mtpp_mean_all/best_134150"     --model_name "mtpp"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/"       --ontology_path "/user/zj2398/cache/mtpp_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/mtpp/"       --task_type binary       --loss_type labeled_subjects 
/user/zj2398/.conda/envs/tte/bin/python: Error while finding module specification for 'femr.omop_meds_tutorial.motor_evaluation.generate_mtpp_features' (ModuleNotFoundError: No module named 'femr.omop_meds_tutorial.motor_evaluation')
Error: mtpp feature generation failed for task celiac
[2/3] Processing task: masld
cohort_base_dir: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
Task directory: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/masld/
Running mtpp feature generation for masld...
Executing command: python -u -m femr.omop_meds_tutorial.motor_evaluation.generate_mtpp_features       --pretraining_data "/user/zj2398/cache/mtpp_8k"       --model_path "/user/zj2398/cache/mtpp_8k/mtpp_mean_all/best_134150"     --model_name "mtpp"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/phenotype_task/cohort/masld/"       --ontology_path "/user/zj2398/cache/mtpp_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/mtpp/"       --task_type binary       --loss_type labeled_subjects 
/user/zj2398/.conda/envs/tte/bin/python: Error while finding module specification for 'femr.omop_meds_tutorial.motor_evaluation.generate_mtpp_features' (ModuleNotFoundError: No module named 'femr.omop_meds_tutorial.motor_evaluation')
Error: mtpp feature generation failed for task masld
[3/3] Processing task: stroke
cohort_base_dir: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
Task directory: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/stroke/
Running mtpp feature generation for stroke...
Executing command: python -u -m femr.omop_meds_tutorial.motor_evaluation.generate_mtpp_features       --pretraining_data "/user/zj2398/cache/mtpp_8k"       --model_path "/user/zj2398/cache/mtpp_8k/mtpp_mean_all/best_134150"     --model_name "mtpp"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/phenotype_task/cohort/stroke/"       --ontology_path "/user/zj2398/cache/mtpp_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/mtpp/"       --task_type binary       --loss_type labeled_subjects 
/user/zj2398/.conda/envs/tte/bin/python: Error while finding module specification for 'femr.omop_meds_tutorial.motor_evaluation.generate_mtpp_features' (ModuleNotFoundError: No module named 'femr.omop_meds_tutorial.motor_evaluation')
Error: mtpp feature generation failed for task stroke
All tasks processed.
Using configuration:
  COHORT_BASE_DIR: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
  PRETRAINING_DATA: /user/zj2398/cache/mtpp_8k
  OMOP_MEDS_READER: /user/zj2398/cache/mimic/meds_v0.6_reader
  NUM_PROC: 64
  TOKENS_PER_BATCH: 65536
  OBSERVATION_WINDOW: Not specified
  USE_LINEAR_INTERPOLATION: false

Discovering prediction tasks...
[1] Found task: celiac
[2] Found task: masld
[3] Found task: stroke
[1/3] Processing task: celiac
cohort_base_dir: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
Task directory: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/
Running mtpp feature generation for celiac...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_mtpp_features       --pretraining_data "/user/zj2398/cache/mtpp_8k"       --model_path "/user/zj2398/cache/mtpp_8k/mtpp_mean_all/best_134150"     --model_name "mtpp"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/"       --ontology_path "/user/zj2398/cache/mtpp_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/mtpp/"       --task_type binary       --loss_type labeled_subjects 
label_name of cohort_dir: celiac
/shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/celiac_cohort.parquet
Loading labels from  /shared/share_mala/zj2398/mimic/phenotype_task/mtpp/labels/celiac.parquet
labels head:    subject_id     prediction_time  boolean_value  tte_label  time_to_event_days
0    10314601 2207-09-26 14:54:00          False      False          796.056944
1    10314601 2208-10-26 12:31:00          False      False          400.156250
2    10314601 2209-04-25 06:47:00          False      False          219.395139
3    10315300 2126-05-18 15:46:00          False      False         1061.767361
4    10315300 2126-09-02 18:00:00          False      False          954.674306
task type is binary
typed_labels length: 150188
Loading model from /user/zj2398/cache/mtpp_8k/mtpp_mean_all/best_134150
use_linear_interpolation: False
loss type is labeled_subjects
starting loading model
the hidden size is 768
create loss type is labeled_subjects
the report is LoadReport(renamed_keys=[('transformer.embed_bag.weight', 'backbone.embed_bag.weight'), ('transformer.in_norm.weight', 'backbone.in_norm.weight'), ('transformer.layers.0.input_proj.weight', 'backbone.layers.0.input_proj.weight'), ('transformer.layers.0.norm.weight', 'backbone.layers.0.norm.weight'), ('transformer.layers.0.output_proj.weight', 'backbone.layers.0.output_proj.weight'), ('transformer.layers.1.input_proj.weight', 'backbone.layers.1.input_proj.weight'), ('transformer.layers.1.norm.weight', 'backbone.layers.1.norm.weight'), ('transformer.layers.1.output_proj.weight', 'backbone.layers.1.output_proj.weight'), ('transformer.layers.10.input_proj.weight', 'backbone.layers.10.input_proj.weight'), ('transformer.layers.10.norm.weight', 'backbone.layers.10.norm.weight'), ('transformer.layers.10.output_proj.weight', 'backbone.layers.10.output_proj.weight'), ('transformer.layers.2.input_proj.weight', 'backbone.layers.2.input_proj.weight'), ('transformer.layers.2.norm.weight', 'backbone.layers.2.norm.weight'), ('transformer.layers.2.output_proj.weight', 'backbone.layers.2.output_proj.weight'), ('transformer.layers.3.input_proj.weight', 'backbone.layers.3.input_proj.weight'), ('transformer.layers.3.norm.weight', 'backbone.layers.3.norm.weight'), ('transformer.layers.3.output_proj.weight', 'backbone.layers.3.output_proj.weight'), ('transformer.layers.4.input_proj.weight', 'backbone.layers.4.input_proj.weight'), ('transformer.layers.4.norm.weight', 'backbone.layers.4.norm.weight'), ('transformer.layers.4.output_proj.weight', 'backbone.layers.4.output_proj.weight'), ('transformer.layers.5.input_proj.weight', 'backbone.layers.5.input_proj.weight'), ('transformer.layers.5.norm.weight', 'backbone.layers.5.norm.weight'), ('transformer.layers.5.output_proj.weight', 'backbone.layers.5.output_proj.weight'), ('transformer.layers.6.input_proj.weight', 'backbone.layers.6.input_proj.weight'), ('transformer.layers.6.norm.weight', 'backbone.layers.6.norm.weight'), ('transformer.layers.6.output_proj.weight', 'backbone.layers.6.output_proj.weight'), ('transformer.layers.7.input_proj.weight', 'backbone.layers.7.input_proj.weight'), ('transformer.layers.7.norm.weight', 'backbone.layers.7.norm.weight'), ('transformer.layers.7.output_proj.weight', 'backbone.layers.7.output_proj.weight'), ('transformer.layers.8.input_proj.weight', 'backbone.layers.8.input_proj.weight'), ('transformer.layers.8.norm.weight', 'backbone.layers.8.norm.weight'), ('transformer.layers.8.output_proj.weight', 'backbone.layers.8.output_proj.weight'), ('transformer.layers.9.input_proj.weight', 'backbone.layers.9.input_proj.weight'), ('transformer.layers.9.norm.weight', 'backbone.layers.9.norm.weight'), ('transformer.layers.9.output_proj.weight', 'backbone.layers.9.output_proj.weight'), ('transformer.out_norm.weight', 'backbone.out_norm.weight')], dropped_keys=['task_model.logvars', 'task_model.non_numerical_final_layer.bias', 'task_model.non_numerical_final_layer.weight', 'task_model.non_numerical_task_layer.bias', 'task_model.non_numerical_task_layer.weight', 'task_model.norm.weight', 'task_model.numerical_final_layer.bias', 'task_model.numerical_final_layer.weight', 'task_model.numerical_task_layer.bias', 'task_model.numerical_task_layer.weight'], missing_keys=[], unexpected_keys=[])
The maximum context length is 8192.0,  8 subjects and 65536 tokens per batch
max_length: 8192
Using configuration:
  COHORT_BASE_DIR: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/
  PRETRAINING_DATA: /user/zj2398/cache/mtpp_8k
  OMOP_MEDS_READER: /user/zj2398/cache/mimic/meds_v0.6_reader
  NUM_PROC: 64
  TOKENS_PER_BATCH: 65536
  OBSERVATION_WINDOW: Not specified
  USE_LINEAR_INTERPOLATION: false

Discovering prediction tasks...
[1] Found task: in_hospital_mortality
[2] Found task: long_los
[3] Found task: readmission
[1/3] Processing task: in_hospital_mortality
cohort_base_dir: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/
Task directory: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/
Running mtpp_mean_all feature generation for in_hospital_mortality...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_mtpp_features       --pretraining_data "/user/zj2398/cache/mtpp_8k"       --model_path "/user/zj2398/cache/mtpp_8k/mtpp_mean_all/best_134150"     --model_name "mtpp_mean_all"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/"       --ontology_path "/user/zj2398/cache/mtpp_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/patient_outcome_tasks/mtpp/"       --task_type binary       --loss_type labeled_subjects 
label_name of cohort_dir: in_hospital_mortality
/shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/train.parquet
/shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/tuning.parquet
/shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/held_out.parquet
Loading labels from  /shared/share_mala/zj2398/mimic/patient_outcome_tasks/mtpp/labels/in_hospital_mortality.parquet
labels head:    subject_id     prediction_time  ...  float_value  categorical_value
0    10017886 2140-12-17 18:55:00  ...          NaN               None
1    10017886 2141-04-30 02:37:00  ...          NaN               None
2    10017886 2141-05-11 21:25:00  ...          NaN               None
3    10018297 2115-02-04 22:10:00  ...          NaN               None
4    10026879 2159-04-11 17:06:00  ...          NaN               None

[5 rows x 6 columns]
task type is binary
typed_labels length: 331592
Loading model from /user/zj2398/cache/mtpp_8k/mtpp_mean_all/best_134150
use_linear_interpolation: False
loss type is labeled_subjects
starting loading model
the hidden size is 768
create loss type is labeled_subjects
the report is LoadReport(renamed_keys=[('transformer.embed_bag.weight', 'backbone.embed_bag.weight'), ('transformer.in_norm.weight', 'backbone.in_norm.weight'), ('transformer.layers.0.input_proj.weight', 'backbone.layers.0.input_proj.weight'), ('transformer.layers.0.norm.weight', 'backbone.layers.0.norm.weight'), ('transformer.layers.0.output_proj.weight', 'backbone.layers.0.output_proj.weight'), ('transformer.layers.1.input_proj.weight', 'backbone.layers.1.input_proj.weight'), ('transformer.layers.1.norm.weight', 'backbone.layers.1.norm.weight'), ('transformer.layers.1.output_proj.weight', 'backbone.layers.1.output_proj.weight'), ('transformer.layers.10.input_proj.weight', 'backbone.layers.10.input_proj.weight'), ('transformer.layers.10.norm.weight', 'backbone.layers.10.norm.weight'), ('transformer.layers.10.output_proj.weight', 'backbone.layers.10.output_proj.weight'), ('transformer.layers.2.input_proj.weight', 'backbone.layers.2.input_proj.weight'), ('transformer.layers.2.norm.weight', 'backbone.layers.2.norm.weight'), ('transformer.layers.2.output_proj.weight', 'backbone.layers.2.output_proj.weight'), ('transformer.layers.3.input_proj.weight', 'backbone.layers.3.input_proj.weight'), ('transformer.layers.3.norm.weight', 'backbone.layers.3.norm.weight'), ('transformer.layers.3.output_proj.weight', 'backbone.layers.3.output_proj.weight'), ('transformer.layers.4.input_proj.weight', 'backbone.layers.4.input_proj.weight'), ('transformer.layers.4.norm.weight', 'backbone.layers.4.norm.weight'), ('transformer.layers.4.output_proj.weight', 'backbone.layers.4.output_proj.weight'), ('transformer.layers.5.input_proj.weight', 'backbone.layers.5.input_proj.weight'), ('transformer.layers.5.norm.weight', 'backbone.layers.5.norm.weight'), ('transformer.layers.5.output_proj.weight', 'backbone.layers.5.output_proj.weight'), ('transformer.layers.6.input_proj.weight', 'backbone.layers.6.input_proj.weight'), ('transformer.layers.6.norm.weight', 'backbone.layers.6.norm.weight'), ('transformer.layers.6.output_proj.weight', 'backbone.layers.6.output_proj.weight'), ('transformer.layers.7.input_proj.weight', 'backbone.layers.7.input_proj.weight'), ('transformer.layers.7.norm.weight', 'backbone.layers.7.norm.weight'), ('transformer.layers.7.output_proj.weight', 'backbone.layers.7.output_proj.weight'), ('transformer.layers.8.input_proj.weight', 'backbone.layers.8.input_proj.weight'), ('transformer.layers.8.norm.weight', 'backbone.layers.8.norm.weight'), ('transformer.layers.8.output_proj.weight', 'backbone.layers.8.output_proj.weight'), ('transformer.layers.9.input_proj.weight', 'backbone.layers.9.input_proj.weight'), ('transformer.layers.9.norm.weight', 'backbone.layers.9.norm.weight'), ('transformer.layers.9.output_proj.weight', 'backbone.layers.9.output_proj.weight'), ('transformer.out_norm.weight', 'backbone.out_norm.weight')], dropped_keys=['task_model.logvars', 'task_model.non_numerical_final_layer.bias', 'task_model.non_numerical_final_layer.weight', 'task_model.non_numerical_task_layer.bias', 'task_model.non_numerical_task_layer.weight', 'task_model.norm.weight', 'task_model.numerical_final_layer.bias', 'task_model.numerical_final_layer.weight', 'task_model.numerical_task_layer.bias', 'task_model.numerical_task_layer.weight'], missing_keys=[], unexpected_keys=[])
The maximum context length is 8192.0,  8 subjects and 65536 tokens per batch
max_length: 8192
Got batches 4720
Error: Cohort base directory does not exist: /user/zj2398/cache/mimic/mimic-3.1-meds/phenotype_task/
Using configuration:
  COHORT_BASE_DIR: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
  PRETRAINING_DATA: /user/zj2398/cache/motor_mimic_8k
  OMOP_MEDS_READER: /user/zj2398/cache/mimic/meds_v0.6_reader
  NUM_PROC: 64
  TOKENS_PER_BATCH: 65536
  OBSERVATION_WINDOW: Not specified
  USE_LINEAR_INTERPOLATION: false

Discovering prediction tasks...
[1] Found task: celiac
[2] Found task: masld
[3] Found task: stroke
[1/3] Processing task: celiac
cohort_base_dir: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
Task directory: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/
Running motor feature generation for celiac...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_motor_features       --pretraining_data "/user/zj2398/cache/motor_mimic_8k"       --model_path "/user/zj2398/cache/motor_mimic_8k/output/best_100620"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/"       --ontology_path "/user/zj2398/cache/motor_mimic_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/motor/"       --task_type binary       --loss_type labeled_subjects 
usage: generate_motor_features.py [-h] --pretraining_data PRETRAINING_DATA
                                  --meds_reader MEDS_READER
                                  [--num_proc NUM_PROC]
                                  [--model_path MODEL_PATH]
                                  [--model_name MODEL_NAME] [--device DEVICE]
                                  [--tokens_per_batch TOKENS_PER_BATCH]
                                  [--cohort_dir COHORT_DIR]
                                  [--observation_window OBSERVATION_WINDOW]
                                  [--min_subjects_per_batch MIN_SUBJECTS_PER_BATCH]
                                  [--ontology_path ONTOLOGY_PATH]
                                  [--linear_interpolation]
                                  [--loss_type LOSS_TYPE]
generate_motor_features.py: error: unrecognized arguments: --output_root /shared/share_mala/zj2398/mimic/phenotype_task/motor/ --task_type binary
Error: motor feature generation failed for task celiac
[2/3] Processing task: masld
cohort_base_dir: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
Task directory: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/masld/
Running motor feature generation for masld...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_motor_features       --pretraining_data "/user/zj2398/cache/motor_mimic_8k"       --model_path "/user/zj2398/cache/motor_mimic_8k/output/best_100620"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/phenotype_task/cohort/masld/"       --ontology_path "/user/zj2398/cache/motor_mimic_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/motor/"       --task_type binary       --loss_type labeled_subjects 
usage: generate_motor_features.py [-h] --pretraining_data PRETRAINING_DATA
                                  --meds_reader MEDS_READER
                                  [--num_proc NUM_PROC]
                                  [--model_path MODEL_PATH]
                                  [--model_name MODEL_NAME] [--device DEVICE]
                                  [--tokens_per_batch TOKENS_PER_BATCH]
                                  [--cohort_dir COHORT_DIR]
                                  [--observation_window OBSERVATION_WINDOW]
                                  [--min_subjects_per_batch MIN_SUBJECTS_PER_BATCH]
                                  [--ontology_path ONTOLOGY_PATH]
                                  [--linear_interpolation]
                                  [--loss_type LOSS_TYPE]
generate_motor_features.py: error: unrecognized arguments: --output_root /shared/share_mala/zj2398/mimic/phenotype_task/motor/ --task_type binary
Error: motor feature generation failed for task masld
[3/3] Processing task: stroke
cohort_base_dir: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
Task directory: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/stroke/
Running motor feature generation for stroke...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_motor_features       --pretraining_data "/user/zj2398/cache/motor_mimic_8k"       --model_path "/user/zj2398/cache/motor_mimic_8k/output/best_100620"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/phenotype_task/cohort/stroke/"       --ontology_path "/user/zj2398/cache/motor_mimic_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/motor/"       --task_type binary       --loss_type labeled_subjects 
Using configuration:
  COHORT_BASE_DIR: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/
  PRETRAINING_DATA: /user/zj2398/cache/motor_mimic_8k
  OMOP_MEDS_READER: /user/zj2398/cache/mimic/meds_v0.6_reader
  NUM_PROC: 64
  TOKENS_PER_BATCH: 65536
  OBSERVATION_WINDOW: Not specified
  USE_LINEAR_INTERPOLATION: false

Discovering prediction tasks...
[1] Found task: in_hospital_mortality
[2] Found task: long_los
[3] Found task: readmission
[1/3] Processing task: in_hospital_mortality
cohort_base_dir: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/
Task directory: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/
Running motor feature generation for in_hospital_mortality...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_motor_features       --pretraining_data "/user/zj2398/cache/motor_mimic_8k"       --model_path "/user/zj2398/cache/motor_mimic_8k/output/best_100620"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/"       --ontology_path "/user/zj2398/cache/motor_mimic_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/motor/"       --task_type binary       --loss_type labeled_subjects 
usage: generate_motor_features.py [-h] --pretraining_data PRETRAINING_DATA
                                  --meds_reader MEDS_READER
                                  [--num_proc NUM_PROC]
                                  [--model_path MODEL_PATH]
                                  [--model_name MODEL_NAME] [--device DEVICE]
                                  [--tokens_per_batch TOKENS_PER_BATCH]
                                  [--cohort_dir COHORT_DIR]
                                  [--observation_window OBSERVATION_WINDOW]
                                  [--min_subjects_per_batch MIN_SUBJECTS_PER_BATCH]
                                  [--ontology_path ONTOLOGY_PATH]
                                  [--linear_interpolation]
                                  [--loss_type LOSS_TYPE]
generate_motor_features.py: error: unrecognized arguments: --output_root /shared/share_mala/zj2398/mimic/phenotype_task/motor/ --task_type binary
Error: motor feature generation failed for task stroke
All tasks processed.
usage: generate_motor_features.py [-h] --pretraining_data PRETRAINING_DATA
                                  --meds_reader MEDS_READER
                                  [--num_proc NUM_PROC]
                                  [--model_path MODEL_PATH]
                                  [--model_name MODEL_NAME] [--device DEVICE]
                                  [--tokens_per_batch TOKENS_PER_BATCH]
                                  [--cohort_dir COHORT_DIR]
                                  [--observation_window OBSERVATION_WINDOW]
                                  [--min_subjects_per_batch MIN_SUBJECTS_PER_BATCH]
                                  [--ontology_path ONTOLOGY_PATH]
                                  [--linear_interpolation]
                                  [--loss_type LOSS_TYPE]
generate_motor_features.py: error: unrecognized arguments: --output_root /shared/share_mala/zj2398/mimic/phenotype_task/motor/ --task_type binary
Error: motor feature generation failed for task in_hospital_mortality
[2/3] Processing task: long_los
cohort_base_dir: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/
Task directory: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/long_los/
Running motor feature generation for long_los...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_motor_features       --pretraining_data "/user/zj2398/cache/motor_mimic_8k"       --model_path "/user/zj2398/cache/motor_mimic_8k/output/best_100620"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/long_los/"       --ontology_path "/user/zj2398/cache/motor_mimic_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/motor/"       --task_type binary       --loss_type labeled_subjects 
usage: generate_motor_features.py [-h] --pretraining_data PRETRAINING_DATA
                                  --meds_reader MEDS_READER
                                  [--num_proc NUM_PROC]
                                  [--model_path MODEL_PATH]
                                  [--model_name MODEL_NAME] [--device DEVICE]
                                  [--tokens_per_batch TOKENS_PER_BATCH]
                                  [--cohort_dir COHORT_DIR]
                                  [--observation_window OBSERVATION_WINDOW]
                                  [--min_subjects_per_batch MIN_SUBJECTS_PER_BATCH]
                                  [--ontology_path ONTOLOGY_PATH]
                                  [--linear_interpolation]
                                  [--loss_type LOSS_TYPE]
generate_motor_features.py: error: unrecognized arguments: --output_root /shared/share_mala/zj2398/mimic/phenotype_task/motor/ --task_type binary
Error: motor feature generation failed for task long_los
[3/3] Processing task: readmission
cohort_base_dir: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/
Task directory: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/readmission/
Running motor feature generation for readmission...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_motor_features       --pretraining_data "/user/zj2398/cache/motor_mimic_8k"       --model_path "/user/zj2398/cache/motor_mimic_8k/output/best_100620"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/readmission/"       --ontology_path "/user/zj2398/cache/motor_mimic_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/motor/"       --task_type binary       --loss_type labeled_subjects 
usage: generate_motor_features.py [-h] --pretraining_data PRETRAINING_DATA
                                  --meds_reader MEDS_READER
                                  [--num_proc NUM_PROC]
                                  [--model_path MODEL_PATH]
                                  [--model_name MODEL_NAME] [--device DEVICE]
                                  [--tokens_per_batch TOKENS_PER_BATCH]
                                  [--cohort_dir COHORT_DIR]
                                  [--observation_window OBSERVATION_WINDOW]
                                  [--min_subjects_per_batch MIN_SUBJECTS_PER_BATCH]
                                  [--ontology_path ONTOLOGY_PATH]
                                  [--linear_interpolation]
                                  [--loss_type LOSS_TYPE]
generate_motor_features.py: error: unrecognized arguments: --output_root /shared/share_mala/zj2398/mimic/phenotype_task/motor/ --task_type binary
Error: motor feature generation failed for task readmission
All tasks processed.
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 1 examples [02:19, 139.35s/ examples]Generating train split: 2 examples [02:21, 58.63s/ examples] Generating train split: 3 examples [02:25, 33.48s/ examples]Generating train split: 4 examples [02:28, 21.82s/ examples]Generating train split: 5 examples [02:31, 14.93s/ examples]Generating train split: 6 examples [02:34, 10.86s/ examples]Generating train split: 7 examples [02:35,  7.72s/ examples]Generating train split: 8 examples [02:38,  6.25s/ examples]Generating train split: 9 examples [02:40,  4.76s/ examples]Generating train split: 10 examples [02:44,  4.47s/ examples]Generating train split: 11 examples [02:46,  3.88s/ examples]Generating train split: 12 examples [02:50,  3.75s/ examples]Generating train split: 13 examples [02:52,  3.16s/ examples]Generating train split: 14 examples [02:55,  3.34s/ examples]Generating train split: 16 examples [02:59,  2.69s/ examples]Generating train split: 17 examples [03:01,  2.42s/ examples]Generating train split: 18 examples [03:03,  2.37s/ examples]Generating train split: 19 examples [03:06,  2.48s/ examples]Generating train split: 20 examples [03:08,  2.42s/ examples]Generating train split: 21 examples [03:10,  2.22s/ examples]Using configuration:
  COHORT_BASE_DIR: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
  PRETRAINING_DATA: /user/zj2398/cache/motor_mimic_8k
  OMOP_MEDS_READER: /user/zj2398/cache/mimic/meds_v0.6_reader
  NUM_PROC: 64
  TOKENS_PER_BATCH: 65536
  OBSERVATION_WINDOW: Not specified
  USE_LINEAR_INTERPOLATION: false

Discovering prediction tasks...
[1] Found task: celiac
[2] Found task: masld
[3] Found task: stroke
[1/3] Processing task: celiac
cohort_base_dir: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
Task directory: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/
Running motor feature generation for celiac...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_motor_features       --pretraining_data "/user/zj2398/cache/motor_mimic_8k"       --model_path "/user/zj2398/cache/motor_mimic_8k/output/best_100620"       --model_name "motor"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/"       --ontology_path "/user/zj2398/cache/motor_mimic_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/motor/"       --task_type binary       --loss_type labeled_subjects 
Traceback (most recent call last):
  File "<frozen runpy>", line 189, in _run_module_as_main
  File "<frozen runpy>", line 159, in _get_module_details
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/user/zj2398/femr_chao_meds_v3/src/femr/omop_meds_tutorial/evaluation/generate_motor_features.py", line 185
    continue
    ^^^^^^^^
SyntaxError: 'continue' not properly in loop
Error: motor feature generation failed for task celiac
[2/3] Processing task: masld
cohort_base_dir: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
Task directory: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/masld/
Running motor feature generation for masld...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_motor_features       --pretraining_data "/user/zj2398/cache/motor_mimic_8k"       --model_path "/user/zj2398/cache/motor_mimic_8k/output/best_100620"       --model_name "motor"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/phenotype_task/cohort/masld/"       --ontology_path "/user/zj2398/cache/motor_mimic_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/motor/"       --task_type binary       --loss_type labeled_subjects 
Traceback (most recent call last):
  File "<frozen runpy>", line 189, in _run_module_as_main
  File "<frozen runpy>", line 159, in _get_module_details
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/user/zj2398/femr_chao_meds_v3/src/femr/omop_meds_tutorial/evaluation/generate_motor_features.py", line 185
    continue
    ^^^^^^^^
SyntaxError: 'continue' not properly in loop
Error: motor feature generation failed for task masld
[3/3] Processing task: stroke
cohort_base_dir: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
Task directory: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/stroke/
Running motor feature generation for stroke...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_motor_features       --pretraining_data "/user/zj2398/cache/motor_mimic_8k"       --model_path "/user/zj2398/cache/motor_mimic_8k/output/best_100620"       --model_name "motor"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/phenotype_task/cohort/stroke/"       --ontology_path "/user/zj2398/cache/motor_mimic_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/motor/"       --task_type binary       --loss_type labeled_subjects 
Traceback (most recent call last):
  File "<frozen runpy>", line 189, in _run_module_as_main
  File "<frozen runpy>", line 159, in _get_module_details
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/user/zj2398/femr_chao_meds_v3/src/femr/omop_meds_tutorial/evaluation/generate_motor_features.py", line 185
    continue
    ^^^^^^^^
SyntaxError: 'continue' not properly in loop
Error: motor feature generation failed for task stroke
All tasks processed.
Generating train split: 22 examples [03:12,  2.30s/ examples]Generating train split: 23 examples [03:16,  2.56s/ examples]Generating train split: 24 examples [03:21,  3.43s/ examples]Generating train split: 25 examples [03:25,  3.62s/ examples]Generating train split: 26 examples [03:26,  2.82s/ examples]Generating train split: 27 examples [03:30,  3.17s/ examples]Generating train split: 28 examples [03:33,  3.05s/ examples]Generating train split: 29 examples [03:39,  3.86s/ examples]Generating train split: 30 examples [03:41,  3.35s/ examples]Using configuration:
  COHORT_BASE_DIR: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
  PRETRAINING_DATA: /user/zj2398/cache/motor_mimic_8k
  OMOP_MEDS_READER: /user/zj2398/cache/mimic/meds_v0.6_reader
  NUM_PROC: 64
  TOKENS_PER_BATCH: 65536
  OBSERVATION_WINDOW: Not specified
  USE_LINEAR_INTERPOLATION: false

Discovering prediction tasks...
[1] Found task: celiac
[2] Found task: masld
[3] Found task: stroke
[1/3] Processing task: celiac
cohort_base_dir: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/
Task directory: /shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/
Running motor feature generation for celiac...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_motor_features       --pretraining_data "/user/zj2398/cache/motor_mimic_8k"       --model_path "/user/zj2398/cache/motor_mimic_8k/output/best_100620"       --model_name "motor"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/"       --ontology_path "/user/zj2398/cache/motor_mimic_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/motor/"       --task_type binary       --loss_type labeled_subjects 
Generating train split: 31 examples [03:43,  3.15s/ examples]Generating train split: 32 examples [03:47,  3.22s/ examples]Generating train split: 33 examples [03:51,  3.39s/ examples]Generating train split: 34 examples [03:53,  3.22s/ examples]Generating train split: 35 examples [03:56,  2.94s/ examples]Generating train split: 36 examples [03:58,  2.65s/ examples]Generating train split: 37 examples [04:00,  2.45s/ examples]Using configuration:
  COHORT_BASE_DIR: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/
  PRETRAINING_DATA: /user/zj2398/cache/motor_mimic_8k
  OMOP_MEDS_READER: /user/zj2398/cache/mimic/meds_v0.6_reader
  NUM_PROC: 64
  TOKENS_PER_BATCH: 65536
  OBSERVATION_WINDOW: Not specified
  USE_LINEAR_INTERPOLATION: false

Discovering prediction tasks...
[1] Found task: in_hospital_mortality
[2] Found task: long_los
[3] Found task: readmission
[1/3] Processing task: in_hospital_mortality
cohort_base_dir: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/
Task directory: /shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/
Running motor feature generation for in_hospital_mortality...
Executing command: python -u -m femr.omop_meds_tutorial.evaluation.generate_motor_features       --pretraining_data "/user/zj2398/cache/motor_mimic_8k"       --model_path "/user/zj2398/cache/motor_mimic_8k/output/best_100620"       --model_name "motor"       --meds_reader "/user/zj2398/cache/mimic/meds_v0.6_reader"       --num_proc "64"       --tokens_per_batch "65536"       --device "cuda:0"       --min_subjects_per_batch "8"       --cohort_dir "/shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/"       --ontology_path "/user/zj2398/cache/motor_mimic_8k/ontology.pkl"       --output_root "/shared/share_mala/zj2398/mimic/phenotype_task/motor/"       --task_type binary       --loss_type labeled_subjects 
Generating train split: 38 examples [04:02,  2.58s/ examples]Generating train split: 39 examples [04:05,  2.69s/ examples]Generating train split: 40 examples [04:09,  2.94s/ examples]Generating train split: 41 examples [04:10,  2.24s/ examples]Generating train split: 42 examples [04:12,  2.20s/ examples]Generating train split: 43 examples [04:14,  2.13s/ examples]Generating train split: 44 examples [04:14,  1.62s/ examples]Generating train split: 45 examples [04:16,  1.61s/ examples]label_name of cohort_dir: celiac
/shared/share_mala/zj2398/mimic/phenotype_task/cohort/celiac/celiac_cohort.parquet
Loading labels from  /shared/share_mala/zj2398/mimic/phenotype_task/motor/labels/celiac.parquet
labels head:    subject_id     prediction_time  boolean_value  tte_label  time_to_event_days
0    10314601 2207-09-26 14:54:00          False      False          796.056944
1    10314601 2208-10-26 12:31:00          False      False          400.156250
2    10314601 2209-04-25 06:47:00          False      False          219.395139
3    10315300 2126-05-18 15:46:00          False      False         1061.767361
4    10315300 2126-09-02 18:00:00          False      False          954.674306
task type is binary
Generating train split: 46 examples [04:18,  1.91s/ examples]Generating train split: 47 examples [04:19,  1.49s/ examples]typed_labels length: 150188
Loading model from /user/zj2398/cache/motor_mimic_8k/output/best_100620
use_linear_interpolation: False
loss type is labeled_subjects
starting loading model
the hidden size is 768
create loss type is labeled_subjects
the report is LoadReport(renamed_keys=[('transformer.embed_bag.weight', 'backbone.embed_bag.weight'), ('transformer.in_norm.weight', 'backbone.in_norm.weight'), ('transformer.layers.0.input_proj.weight', 'backbone.layers.0.input_proj.weight'), ('transformer.layers.0.norm.weight', 'backbone.layers.0.norm.weight'), ('transformer.layers.0.output_proj.weight', 'backbone.layers.0.output_proj.weight'), ('transformer.layers.1.input_proj.weight', 'backbone.layers.1.input_proj.weight'), ('transformer.layers.1.norm.weight', 'backbone.layers.1.norm.weight'), ('transformer.layers.1.output_proj.weight', 'backbone.layers.1.output_proj.weight'), ('transformer.layers.10.input_proj.weight', 'backbone.layers.10.input_proj.weight'), ('transformer.layers.10.norm.weight', 'backbone.layers.10.norm.weight'), ('transformer.layers.10.output_proj.weight', 'backbone.layers.10.output_proj.weight'), ('transformer.layers.2.input_proj.weight', 'backbone.layers.2.input_proj.weight'), ('transformer.layers.2.norm.weight', 'backbone.layers.2.norm.weight'), ('transformer.layers.2.output_proj.weight', 'backbone.layers.2.output_proj.weight'), ('transformer.layers.3.input_proj.weight', 'backbone.layers.3.input_proj.weight'), ('transformer.layers.3.norm.weight', 'backbone.layers.3.norm.weight'), ('transformer.layers.3.output_proj.weight', 'backbone.layers.3.output_proj.weight'), ('transformer.layers.4.input_proj.weight', 'backbone.layers.4.input_proj.weight'), ('transformer.layers.4.norm.weight', 'backbone.layers.4.norm.weight'), ('transformer.layers.4.output_proj.weight', 'backbone.layers.4.output_proj.weight'), ('transformer.layers.5.input_proj.weight', 'backbone.layers.5.input_proj.weight'), ('transformer.layers.5.norm.weight', 'backbone.layers.5.norm.weight'), ('transformer.layers.5.output_proj.weight', 'backbone.layers.5.output_proj.weight'), ('transformer.layers.6.input_proj.weight', 'backbone.layers.6.input_proj.weight'), ('transformer.layers.6.norm.weight', 'backbone.layers.6.norm.weight'), ('transformer.layers.6.output_proj.weight', 'backbone.layers.6.output_proj.weight'), ('transformer.layers.7.input_proj.weight', 'backbone.layers.7.input_proj.weight'), ('transformer.layers.7.norm.weight', 'backbone.layers.7.norm.weight'), ('transformer.layers.7.output_proj.weight', 'backbone.layers.7.output_proj.weight'), ('transformer.layers.8.input_proj.weight', 'backbone.layers.8.input_proj.weight'), ('transformer.layers.8.norm.weight', 'backbone.layers.8.norm.weight'), ('transformer.layers.8.output_proj.weight', 'backbone.layers.8.output_proj.weight'), ('transformer.layers.9.input_proj.weight', 'backbone.layers.9.input_proj.weight'), ('transformer.layers.9.norm.weight', 'backbone.layers.9.norm.weight'), ('transformer.layers.9.output_proj.weight', 'backbone.layers.9.output_proj.weight'), ('transformer.out_norm.weight', 'backbone.out_norm.weight')], dropped_keys=['task_model.final_layer.bias', 'task_model.final_layer.weight', 'task_model.norm.weight', 'task_model.task_layer.bias', 'task_model.task_layer.weight', 'task_model.task_time_bias'], missing_keys=[], unexpected_keys=[])
The maximum context length is 8192.0,  8 subjects and 65536 tokens per batch
max_length: 8192
Generating train split: 48 examples [04:21,  1.60s/ examples]Generating train split: 49 examples [04:21,  1.23s/ examples]Generating train split: 50 examples [04:24,  1.67s/ examples]Generating train split: 51 examples [04:24,  1.22s/ examples]Generating train split: 52 examples [04:25,  1.19s/ examples]Generating train split: 53 examples [04:26,  1.22s/ examples]Generating train split: 54 examples [04:27,  1.10s/ examples]Generating train split: 55 examples [04:29,  1.42s/ examples]Generating train split: 56 examples [04:30,  1.15s/ examples]Generating train split: 57 examples [04:32,  1.36s/ examples]Generating train split: 58 examples [04:33,  1.32s/ examples]Generating train split: 59 examples [04:33,  1.09s/ examples]label_name of cohort_dir: in_hospital_mortality
/shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/train.parquet
/shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/tuning.parquet
/shared/share_mala/zj2398/mimic/patient_outcome_tasks/cohort/in_hospital_mortality/held_out.parquet
Loading labels from  /shared/share_mala/zj2398/mimic/phenotype_task/motor/labels/in_hospital_mortality.parquet
labels head:    subject_id     prediction_time  ...  float_value  categorical_value
0    10017886 2140-12-17 18:55:00  ...          NaN               None
1    10017886 2141-04-30 02:37:00  ...          NaN               None
2    10017886 2141-05-11 21:25:00  ...          NaN               None
3    10018297 2115-02-04 22:10:00  ...          NaN               None
4    10026879 2159-04-11 17:06:00  ...          NaN               None

[5 rows x 6 columns]
task type is binary
Generating train split: 60 examples [04:35,  1.20s/ examples]Generating train split: 61 examples [04:36,  1.21s/ examples]Generating train split: 62 examples [04:37,  1.02 examples/s]typed_labels length: 331592
Loading model from /user/zj2398/cache/motor_mimic_8k/output/best_100620
use_linear_interpolation: False
loss type is labeled_subjects
starting loading model
the hidden size is 768
create loss type is labeled_subjects
the report is LoadReport(renamed_keys=[('transformer.embed_bag.weight', 'backbone.embed_bag.weight'), ('transformer.in_norm.weight', 'backbone.in_norm.weight'), ('transformer.layers.0.input_proj.weight', 'backbone.layers.0.input_proj.weight'), ('transformer.layers.0.norm.weight', 'backbone.layers.0.norm.weight'), ('transformer.layers.0.output_proj.weight', 'backbone.layers.0.output_proj.weight'), ('transformer.layers.1.input_proj.weight', 'backbone.layers.1.input_proj.weight'), ('transformer.layers.1.norm.weight', 'backbone.layers.1.norm.weight'), ('transformer.layers.1.output_proj.weight', 'backbone.layers.1.output_proj.weight'), ('transformer.layers.10.input_proj.weight', 'backbone.layers.10.input_proj.weight'), ('transformer.layers.10.norm.weight', 'backbone.layers.10.norm.weight'), ('transformer.layers.10.output_proj.weight', 'backbone.layers.10.output_proj.weight'), ('transformer.layers.2.input_proj.weight', 'backbone.layers.2.input_proj.weight'), ('transformer.layers.2.norm.weight', 'backbone.layers.2.norm.weight'), ('transformer.layers.2.output_proj.weight', 'backbone.layers.2.output_proj.weight'), ('transformer.layers.3.input_proj.weight', 'backbone.layers.3.input_proj.weight'), ('transformer.layers.3.norm.weight', 'backbone.layers.3.norm.weight'), ('transformer.layers.3.output_proj.weight', 'backbone.layers.3.output_proj.weight'), ('transformer.layers.4.input_proj.weight', 'backbone.layers.4.input_proj.weight'), ('transformer.layers.4.norm.weight', 'backbone.layers.4.norm.weight'), ('transformer.layers.4.output_proj.weight', 'backbone.layers.4.output_proj.weight'), ('transformer.layers.5.input_proj.weight', 'backbone.layers.5.input_proj.weight'), ('transformer.layers.5.norm.weight', 'backbone.layers.5.norm.weight'), ('transformer.layers.5.output_proj.weight', 'backbone.layers.5.output_proj.weight'), ('transformer.layers.6.input_proj.weight', 'backbone.layers.6.input_proj.weight'), ('transformer.layers.6.norm.weight', 'backbone.layers.6.norm.weight'), ('transformer.layers.6.output_proj.weight', 'backbone.layers.6.output_proj.weight'), ('transformer.layers.7.input_proj.weight', 'backbone.layers.7.input_proj.weight'), ('transformer.layers.7.norm.weight', 'backbone.layers.7.norm.weight'), ('transformer.layers.7.output_proj.weight', 'backbone.layers.7.output_proj.weight'), ('transformer.layers.8.input_proj.weight', 'backbone.layers.8.input_proj.weight'), ('transformer.layers.8.norm.weight', 'backbone.layers.8.norm.weight'), ('transformer.layers.8.output_proj.weight', 'backbone.layers.8.output_proj.weight'), ('transformer.layers.9.input_proj.weight', 'backbone.layers.9.input_proj.weight'), ('transformer.layers.9.norm.weight', 'backbone.layers.9.norm.weight'), ('transformer.layers.9.output_proj.weight', 'backbone.layers.9.output_proj.weight'), ('transformer.out_norm.weight', 'backbone.out_norm.weight')], dropped_keys=['task_model.final_layer.bias', 'task_model.final_layer.weight', 'task_model.norm.weight', 'task_model.task_layer.bias', 'task_model.task_layer.weight', 'task_model.task_time_bias'], missing_keys=[], unexpected_keys=[])
Generating train split: 63 examples [04:38,  1.18s/ examples]The maximum context length is 8192.0,  8 subjects and 65536 tokens per batch
max_length: 8192
Generating train split: 64 examples [04:39,  1.20s/ examples]Generating train split: 65 examples [04:41,  1.19s/ examples]Generating train split: 66 examples [04:45,  2.01s/ examples]Generating train split: 69 examples [04:46,  1.21s/ examples]Generating train split: 70 examples [04:48,  1.27s/ examples]Generating train split: 71 examples [04:49,  1.34s/ examples]Generating train split: 72 examples [04:52,  1.58s/ examples]Generating train split: 73 examples [04:54,  1.69s/ examples]