{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe7a3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422757\n",
      "422757\n",
      "1156492\n",
      "1156492\n",
      "3231218\n",
      "3231218\n",
      "3129231\n",
      "3129231\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "disease_dir = Path(\"/shared/share_mala/zj2398/mimic/regression_labels_nona/\")\n",
    "for parquet_file in disease_dir.glob(\"*.parquet\"):\n",
    "    disease_file = pd.read_parquet(parquet_file)\n",
    "    # disease_file = disease_file.dropna(subset=[\"numeric_value\"])\n",
    "    # disease_file.to_parquet(parquet_file)\n",
    "    print(len(disease_file))\n",
    "    # # print(disease_file)\n",
    "    mask_nan = disease_file[\"numeric_value\"].notna()\n",
    "    print(sum(mask_nan))\n",
    "    # print(disease_file.iloc[511934][\"numeric_value\"].dtype())\n",
    "    # print(disease_file[\"numeric_value\"] != float('nan'))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e195ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pao2_regression.parquet\n",
      "        subject_id     prediction_time  numerical_value   unit\n",
      "0         10000935 2187-10-22 15:42:00             86.0  mm Hg\n",
      "18        10001884 2131-01-13 02:31:00             69.0  mm Hg\n",
      "21        10002013 2160-05-18 09:23:00            441.0  mm Hg\n",
      "34        10002155 2129-08-04 12:27:00             89.0  mm Hg\n",
      "43        10002348 2112-12-05 03:52:00            100.0  mm Hg\n",
      "...            ...                 ...              ...    ...\n",
      "511917    19999442 2148-11-19 17:15:00            131.0  mm Hg\n",
      "511921    19999625 2139-10-10 17:31:00             71.0  mm Hg\n",
      "511922    19999828 2149-01-08 10:06:00             77.0  mm Hg\n",
      "511927    19999840 2164-09-13 02:50:00             86.0  mm Hg\n",
      "511937    19999987 2145-11-04 07:20:00             69.0  mm Hg\n",
      "\n",
      "[46953 rows x 4 columns]\n",
      "Kept 46,953 of 422,715 rows within 0 days 00:00:00 of first event.\n",
      "bilirubin_regression.parquet\n",
      "         subject_id     prediction_time  numerical_value   unit\n",
      "9          10000032 2180-07-25 07:44:00              1.7  mg/dL\n",
      "14         10000048 2126-11-23 00:55:00              0.6  mg/dL\n",
      "15         10000084 2160-11-21 00:09:00              0.4  mg/dL\n",
      "17         10000117 2174-06-03 19:57:00              1.1  mg/dL\n",
      "24         10000285 2159-11-26 16:02:00              0.5  mg/dL\n",
      "...             ...                 ...              ...    ...\n",
      "1174781    19999782 2156-11-09 23:05:00              0.2  mg/dL\n",
      "1174782    19999784 2119-06-27 06:59:00              0.3  mg/dL\n",
      "1174892    19999828 2149-01-09 04:20:00              0.3  mg/dL\n",
      "1174898    19999840 2164-09-16 05:42:00              0.7  mg/dL\n",
      "1174901    19999987 2145-11-06 11:19:00              1.9  mg/dL\n",
      "\n",
      "[145236 rows x 4 columns]\n",
      "Kept 145,236 of 1,156,381 rows within 0 days 00:00:00 of first event.\n",
      "creatinine_regression.parquet\n",
      "         subject_id     prediction_time  numerical_value   unit\n",
      "0          10000032 2180-03-23 16:40:00              0.4  mg/dL\n",
      "18         10000048 2126-11-22 21:32:00              0.7  mg/dL\n",
      "19         10000084 2160-11-21 00:09:00              0.8  mg/dL\n",
      "25         10000108 2163-09-27 19:44:00              1.0  mg/dL\n",
      "33         10000117 2181-11-15 09:57:00              0.9  mg/dL\n",
      "...             ...                 ...              ...    ...\n",
      "3282067    19999784 2119-06-28 10:34:00              0.8  mg/dL\n",
      "3282226    19999828 2147-07-27 05:16:00              0.5  mg/dL\n",
      "3282253    19999829 2186-06-14 13:45:00              0.9  mg/dL\n",
      "3282266    19999840 2164-09-16 05:42:00              0.7  mg/dL\n",
      "3282271    19999987 2145-11-03 02:42:00              1.3  mg/dL\n",
      "\n",
      "[239518 rows x 4 columns]\n",
      "Kept 239,518 of 3,230,981 rows within 0 days 00:00:00 of first event.\n",
      "platelets_regression.parquet\n",
      "         subject_id     prediction_time  numerical_value  unit\n",
      "6          10000032 2180-07-23 07:00:00            145.0  K/uL\n",
      "13         10000048 2126-11-22 21:32:00            194.0  K/uL\n",
      "14         10000084 2160-11-20 22:46:00            263.0  K/uL\n",
      "20         10000108 2163-09-27 19:12:00            198.0  K/uL\n",
      "36         10000117 2183-09-19 08:28:00            218.0  K/uL\n",
      "...             ...                 ...              ...   ...\n",
      "3216492    19999784 2119-09-23 07:07:00            312.0  K/uL\n",
      "3216625    19999828 2149-01-09 03:50:00            368.0  K/uL\n",
      "3216635    19999829 2186-06-14 13:17:00            320.0  K/uL\n",
      "3216648    19999840 2164-09-17 13:31:00            288.0  K/uL\n",
      "3216652    19999987 2145-11-05 06:34:00            135.0  K/uL\n",
      "\n",
      "[242041 rows x 4 columns]\n",
      "Kept 242,041 of 3,128,970 rows within 0 days 00:00:00 of first event.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import meds_reader\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "disease_dir = Path(\"/shared/share_mala/zj2398/mimic/regression/cohort/regression_labels_nona\")\n",
    "task=\"bilirubin\"\n",
    "meds_path = \"/user/zj2398/cache/mimic/meds_v0.6_reader\"\n",
    "\n",
    "disease_path = disease_dir/f\"{task}_regression.parquet\"\n",
    "# df = pd.read_parquet(disease_path)\n",
    "\n",
    "database = meds_reader.SubjectDatabase(meds_path)\n",
    "# print(database[10000032])\n",
    "# print(disease_file)\n",
    "# Ensure types\n",
    "for parquet_file in disease_dir.glob(\"*.parquet\"):\n",
    "    print(parquet_file.name)\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    # print(f\"parquet_file {len(df)}\")\n",
    "    df[\"patient_id\"] = df[\"patient_id\"].astype(int)\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "\n",
    "    # 2) Build unique patient list from the dataframe (so we only fetch what we need)\n",
    "    all_pids = df[\"patient_id\"].unique().tolist()\n",
    "\n",
    "    # --- Worker function: open SubjectDatabase inside the process, compute first non-None event time per patient ---\n",
    "    def first_event_times_for_chunk(pids_chunk, meds_path_str):\n",
    "        from datetime import datetime\n",
    "        import meds_reader as _mr\n",
    "\n",
    "        db = _mr.SubjectDatabase(meds_path_str)\n",
    "\n",
    "        out = {}\n",
    "        for pid in pids_chunk:\n",
    "            try:\n",
    "                subj = db[pid]\n",
    "            except KeyError:\n",
    "                # no subject -> skip\n",
    "                continue\n",
    "            first_t = None\n",
    "            for ev in subj.events:\n",
    "                # ev.time can be None; keep the earliest non-None\n",
    "                if ev.time is not None and ev.code != \"MEDS_BIRTH\":\n",
    "                    first_t = ev.time\n",
    "                    break\n",
    "                    # if (first_t is None) or (ev.time < first_t):\n",
    "                    #     first_t = ev.time\n",
    "            if first_t is not None:\n",
    "                out[pid] = pd.Timestamp(first_t)  # normalize to pandas Timestamp\n",
    "        return out\n",
    "\n",
    "    # 3) Parallelize over patient chunks (each worker builds its own SubjectDatabase handle)\n",
    "    def chunked(iterable, size):\n",
    "        for i in range(0, len(iterable), size):\n",
    "            yield iterable[i:i+size]\n",
    "\n",
    "    pid_chunks = list(chunked(all_pids, 1000))\n",
    "    pid_to_first = {}\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=128) as ex:\n",
    "        futs = [ex.submit(first_event_times_for_chunk, ch, str(meds_path)) for ch in pid_chunks]\n",
    "        for fut in as_completed(futs):\n",
    "            pid_to_first.update(fut.result())\n",
    "\n",
    "    # 4) Map first event times back to the dataframe\n",
    "    df[\"first_event_time\"] = df[\"patient_id\"].map(pid_to_first)\n",
    "\n",
    "    # Drop rows for patients with no valid first event time\n",
    "    df = df.dropna(subset=[\"first_event_time\"])\n",
    "\n",
    "    # 5) Keep only rows within the first year after the first event (and not earlier)\n",
    "    observation_window = pd.Timedelta(days=0)\n",
    "    mask = df[\"time\"] >= (df[\"first_event_time\"]+observation_window)\n",
    "    # print(mask,sum(mask))\n",
    "    # print(df)\n",
    "    filtered = df.loc[mask, [\"patient_id\", \"time\", \"numeric_value\", \"unit\"]]  # keep any columns you want\n",
    "    # print(filtered)\n",
    "    # print(filtered.groupby(\"patient_id\",group_keys=False))\n",
    "    filtered = filtered.groupby(\"patient_id\",group_keys=False).sample(n=1,random_state=42)\n",
    "    filtered = filtered.sort_values([\"patient_id\", \"time\"])\n",
    "    filtered = filtered.rename(columns={\n",
    "    \"patient_id\": \"subject_id\",\n",
    "    \"time\": \"prediction_time\",\n",
    "    \"numeric_value\":\"numerical_value\"\n",
    "    })\n",
    "    print(filtered)\n",
    "    # (Optional) Save\n",
    "    # # filtered.to_parquet(\"/path/to/filtered.parquet\", index=False)\n",
    "    store_path = \"/shared/share_mala/zj2398/mimic/regression/cohort/regression_labels_random_drop/\"+ parquet_file.name\n",
    "    filtered.to_parquet(store_path)\n",
    "\n",
    "    print(f\"Kept {len(filtered):,} of {len(df):,} rows within {observation_window} of first event.\")\n",
    "    # break\n",
    "# print(disease_file.iloc[511934][\"numeric_value\"].dtype())\n",
    "# print(disease_file[\"numeric_value\"] != float('nan'))\n",
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50cf5e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      subject_id     prediction_time  y_true      y_pred    residual\n",
      "0       10003637 2150-05-14 18:38:00    29.0  141.474676 -112.474676\n",
      "1       10005866 2148-03-10 16:14:00    87.0  202.922773 -115.922773\n",
      "2       10006053 2111-11-14 00:00:00   137.0  160.296174  -23.296174\n",
      "3       10013097 2135-04-29 17:54:00   142.0  226.328414  -84.328414\n",
      "4       10013419 2168-08-25 11:10:00   106.0  158.802771  -52.802771\n",
      "...          ...                 ...     ...         ...         ...\n",
      "4747    19990821 2143-03-08 13:36:00    79.0  110.636532  -31.636532\n",
      "4748    19993726 2166-09-20 09:15:00   226.0  122.806050  103.193950\n",
      "4749    19995127 2138-06-10 01:08:00    69.0  128.173797  -59.173797\n",
      "4750    19997886 2186-12-09 21:53:00   166.0  122.180077   43.819923\n",
      "4751    19998330 2178-10-22 06:19:00    90.0  106.426063  -16.426063\n",
      "\n",
      "[4752 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pred_path = \"/shared/share_mala/zj2398/mimic/regression/motor/results/pao2/motor/test_predictions.parquet\"\n",
    "pred_reuslt = pd.read_parquet(pred_path)\n",
    "print(pred_reuslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d28795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bilirubin\n",
      "         subject_id     prediction_time  target_value   unit\n",
      "1          10000032 2180-05-06 23:16:00           1.6  mg/dL\n",
      "16         10000084 2160-12-28 05:02:00           0.6  mg/dL\n",
      "18         10000117 2176-02-08 22:43:00           1.1  mg/dL\n",
      "25         10000285 2161-11-08 17:44:00           0.7  mg/dL\n",
      "27         10000560 2189-06-26 14:30:00           0.3  mg/dL\n",
      "...             ...                 ...           ...    ...\n",
      "1174777    19999625 2138-10-06 15:21:00           0.7  mg/dL\n",
      "1174779    19999636 2187-09-15 19:28:00           0.5  mg/dL\n",
      "1174784    19999784 2119-07-31 09:56:00           0.3  mg/dL\n",
      "1174891    19999828 2149-01-08 10:47:00           0.4  mg/dL\n",
      "1174896    19999840 2164-09-12 09:10:00           0.8  mg/dL\n",
      "\n",
      "[95607 rows x 4 columns]\n",
      "creatinine\n",
      "         subject_id     prediction_time  target_value   unit\n",
      "1          10000032 2180-05-06 23:16:00           0.3  mg/dL\n",
      "24         10000084 2160-12-27 20:13:00           0.8  mg/dL\n",
      "27         10000117 2176-02-08 22:43:00           0.9  mg/dL\n",
      "45         10000285 2161-11-08 16:52:00           0.8  mg/dL\n",
      "48         10000560 2189-06-26 14:30:00           0.6  mg/dL\n",
      "...             ...                 ...           ...    ...\n",
      "3282060    19999659 2182-01-07 23:14:00           0.6  mg/dL\n",
      "3282074    19999784 2119-07-24 23:41:00           0.9  mg/dL\n",
      "3282236    19999828 2149-01-08 10:47:00           0.8  mg/dL\n",
      "3282258    19999840 2164-09-11 08:21:00           0.6  mg/dL\n",
      "3282277    19999987 2146-02-07 16:26:00           1.1  mg/dL\n",
      "\n",
      "[141214 rows x 4 columns]\n",
      "pao2\n",
      "        subject_id     prediction_time  target_value   unit\n",
      "0         10000935 2187-10-22 15:42:00          86.0  mm Hg\n",
      "2         10001884 2130-10-10 09:32:00          73.0  mm Hg\n",
      "21        10002013 2160-05-18 09:23:00         441.0  mm Hg\n",
      "34        10002155 2129-08-04 12:27:00          89.0  mm Hg\n",
      "45        10002428 2156-04-19 19:43:00          95.0  mm Hg\n",
      "...            ...                 ...           ...    ...\n",
      "511913    19999287 2197-08-06 18:51:00         217.0  mm Hg\n",
      "511917    19999442 2148-11-19 17:15:00         131.0  mm Hg\n",
      "511921    19999625 2139-10-10 17:31:00          71.0  mm Hg\n",
      "511922    19999828 2149-01-08 10:06:00          77.0  mm Hg\n",
      "511926    19999840 2164-09-12 09:48:00         212.0  mm Hg\n",
      "\n",
      "[27446 rows x 4 columns]\n",
      "platelets\n",
      "         subject_id     prediction_time  target_value  unit\n",
      "1          10000032 2180-05-06 22:42:00          71.0  K/uL\n",
      "19         10000084 2160-12-27 19:43:00         257.0  K/uL\n",
      "22         10000117 2176-02-08 22:24:00         307.0  K/uL\n",
      "45         10000285 2161-11-08 16:17:00         155.0  K/uL\n",
      "48         10000560 2189-06-26 13:44:00         222.0  K/uL\n",
      "...             ...                 ...           ...   ...\n",
      "3216446    19999636 2187-09-15 18:46:00         295.0  K/uL\n",
      "3216448    19999659 2182-01-07 23:08:00         132.0  K/uL\n",
      "3216463    19999784 2119-07-24 22:18:00         268.0  K/uL\n",
      "3216624    19999828 2149-01-08 10:14:00         548.0  K/uL\n",
      "3216640    19999840 2164-09-11 08:00:00         272.0  K/uL\n",
      "\n",
      "[144128 rows x 4 columns]\n",
      "         subject_id     prediction_time  target_value  unit\n",
      "1          10000032 2180-05-06 22:42:00          71.0  K/uL\n",
      "19         10000084 2160-12-27 19:43:00         257.0  K/uL\n",
      "22         10000117 2176-02-08 22:24:00         307.0  K/uL\n",
      "45         10000285 2161-11-08 16:17:00         155.0  K/uL\n",
      "48         10000560 2189-06-26 13:44:00         222.0  K/uL\n",
      "...             ...                 ...           ...   ...\n",
      "3216446    19999636 2187-09-15 18:46:00         295.0  K/uL\n",
      "3216448    19999659 2182-01-07 23:08:00         132.0  K/uL\n",
      "3216463    19999784 2119-07-24 22:18:00         268.0  K/uL\n",
      "3216624    19999828 2149-01-08 10:14:00         548.0  K/uL\n",
      "3216640    19999840 2164-09-11 08:00:00         272.0  K/uL\n",
      "\n",
      "[144128 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pickle as pl\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "def find_overlapping_and_unique_rows(df1, df2, columns):\n",
    "    \"\"\"\n",
    "    Find overlapping and unique rows between two DataFrames based on specified columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find overlapping rows (inner join)\n",
    "    overlapping = df1.merge(df2[columns], on=columns, how='inner')\n",
    "    \n",
    "    # Find unique rows in df1 (left only)\n",
    "    df1_with_indicator = df1.merge(df2[columns], on=columns, how='left', indicator=True)\n",
    "    unique_df1 = df1_with_indicator[df1_with_indicator['_merge'] == 'left_only'].drop('_merge', axis=1)\n",
    "    \n",
    "    # Find unique rows in df2 (right only)\n",
    "    df2_with_indicator = df2.merge(df1[columns], on=columns, how='left', indicator=True)\n",
    "    unique_df2 = df2_with_indicator[df2_with_indicator['_merge'] == 'left_only'].drop('_merge', axis=1)\n",
    "    \n",
    "    return overlapping, unique_df1, unique_df2\n",
    "\n",
    "\n",
    "feature_dir = Path(\"/shared/share_mala/zj2398/mimic/regression/motor/features\")\n",
    "label_dir = Path(\"/shared/share_mala/zj2398/mimic/regression/cohort/regression_labels_1_month\")\n",
    "task = \"bilirubin\"\n",
    "feature_path = feature_dir/f\"{task}_motor.pkl\"\n",
    "with open(feature_path,\"rb\") as f:\n",
    "    feature = pl.load(f)\n",
    "# df = pd.DataFrame(list(feature.items()), columns=['key', 'value'])\n",
    "\n",
    "# print(feature)\n",
    "# feature_df = pd.DataFrame({\n",
    "#         \"subject_id\": feature['subject_ids'],\n",
    "#         \"prediction_time\":feature['feature_times'],\n",
    "#         \"features\": list(feature['features'])\n",
    "#     })\n",
    "# # df = pd.DataFrame([feature])\n",
    "\n",
    "for task in [\"bilirubin\",\"creatinine\",\"pao2\",\"platelets\"]:\n",
    "    print(task)\n",
    "    label_path = label_dir/task/f\"{task}.parquet\"\n",
    "    label_df = pd.read_parquet(label_path)\n",
    "    print(label_df)\n",
    "\n",
    "# print(feature_df)\n",
    "# print(label_df)\n",
    "\n",
    "# overlapping,unique1,unique2 = find_overlapping_and_unique_rows(feature_df, label_df, [\"subject_id\",\"prediction_time\"])\n",
    "# print(f\"overlapping features {overlapping}\")\n",
    "# print(f\"unique df1 {unique1}\")\n",
    "# print(f\"unique df2 {unique2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53804d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
      " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
      " 1.00000000e+01 3.16227766e+01 1.00000000e+02 3.16227766e+02\n",
      " 1.00000000e+03]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.logspace(-3, 3, 13))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tte",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
